name: deepiri-ai-team

# AI Team Docker Compose Configuration
# 
# This file matches the services referenced in:
# - team_dev_environments/ai-team/build.sh
# - team_dev_environments/ai-team/start.sh
# - team_dev_environments/ai-team/stop.sh
#
# Primary services: cyrex, api-gateway, engagement-service, challenge-service, external-bridge-service
# Dependencies: mongodb, redis, influxdb, etcd, minio, milvus, auth-service, task-orchestrator,
#   platform-analytics-service, notification-service, realtime-gateway
#
# IMPORTANT: Set DOCKER_BUILDKIT=1 before building to enable layer caching
# This prevents 50GB+ of dangling images on every build

x-build-args: &build-args
  # Use BuildKit for better caching and no dangling images
  DOCKER_BUILDKIT: 1
  BUILDKIT_PROGRESS: plain

# Minimal logging - logs are automatically cleared and not saved
x-logging: &minimal-logging
  driver: "local"
  options:
    max-size: "1m"      # Only 1MB per file
    max-file: "1"       # Only 1 file (no rotation backup)
    compress: "false"   # No compression (faster cleanup)

services:
  # MongoDB Database
  mongodb:
    image: mongo:7.0
    container_name: deepiri-mongodb-ai
    restart: unless-stopped
    logging: *minimal-logging
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER:-admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD:-password}
      MONGO_INITDB_DATABASE: ${MONGO_DB:-deepiri}
    volumes:
      - mongodb_ai_data:/data/db
      - ./scripts/mongo-init.js:/docker-entrypoint-initdb.d/mongo-init.js:ro
    networks:
      - deepiri-ai-network

  # Redis Cache
  redis:
    image: redis:7.2-alpine
    container_name: deepiri-redis-ai
    restart: unless-stopped
    logging: *minimal-logging
    ports:
      - "6380:6379"
    command: redis-server --requirepass ${REDIS_PASSWORD:-redispassword}
    volumes:
      - redis_ai_data:/data
    networks:
      - deepiri-ai-network

  # InfluxDB for Time-Series Analytics
  influxdb:
    image: influxdb:2.7
    container_name: deepiri-influxdb-ai
    restart: unless-stopped
    logging: *minimal-logging
    ports:
      - "8086:8086"
    environment:
      DOCKER_INFLUXDB_INIT_MODE: setup
      DOCKER_INFLUXDB_INIT_USERNAME: ${INFLUXDB_USER:-admin}
      DOCKER_INFLUXDB_INIT_PASSWORD: ${INFLUXDB_PASSWORD:-adminpassword}
      DOCKER_INFLUXDB_INIT_ORG: ${INFLUXDB_ORG:-deepiri}
      DOCKER_INFLUXDB_INIT_BUCKET: ${INFLUXDB_BUCKET:-analytics}
      DOCKER_INFLUXDB_INIT_ADMIN_TOKEN: ${INFLUXDB_TOKEN:-your-influxdb-token}
    volumes:
      - influxdb_ai_data:/var/lib/influxdb2
    networks:
      - deepiri-ai-network

  # etcd service for Milvus metadata
  etcd:
    image: quay.io/coreos/etcd:v3.5.5
    container_name: deepiri-etcd-ai
    restart: unless-stopped
    logging: *minimal-logging
    environment:
      ETCD_AUTO_COMPACTION_MODE: revision
      ETCD_AUTO_COMPACTION_RETENTION: 1000
      ETCD_QUOTA_BACKEND_BYTES: 4294967296
      ETCD_SNAPSHOT_COUNT: 50000
    volumes:
      - etcd_ai_data:/etcd
    command: etcd -advertise-client-urls=http://127.0.0.1:2379 -listen-client-urls http://0.0.0.0:2379 --data-dir /etcd
    networks:
      - deepiri-ai-network

  # MinIO service for Milvus object storage
  # Updated to latest version (2024) with proper parity settings for data redundancy
  minio:
    image: minio/minio:latest
    container_name: deepiri-minio-ai
    restart: unless-stopped
    logging: *minimal-logging
    environment:
      MINIO_ACCESS_KEY: ${MINIO_ACCESS_KEY:-minioadmin}
      MINIO_SECRET_KEY: ${MINIO_SECRET_KEY:-minioadmin}
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
    volumes:
      - minio_ai_data:/data
    command: minio server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      timeout: 20s
      retries: 3
      start_period: 40s
    ports:
      - "9000:9000"  # API
      - "9001:9001"  # Console
    command: minio server /data --console-address ":9001"
    networks:
      - deepiri-ai-network

  # Milvus Vector Database for RAG
  milvus:
    image: milvusdb/milvus:v2.3.0
    container_name: deepiri-milvus-ai
    restart: unless-stopped
    logging: *minimal-logging
    command: ["milvus", "run", "standalone"]
    ports:
      - "19530:19530"
      - "9091:9091"
    environment:
      ETCD_ENDPOINTS: etcd:2379
      MINIO_ADDRESS: minio:9000
    volumes:
      - milvus_ai_data:/var/lib/milvus
    depends_on:
      - etcd
      - minio
    networks:
      - deepiri-ai-network

  # Python Agent API (AI Service)
  cyrex:
    build:
      context: ./diri-cyrex
      dockerfile: Dockerfile
      args:
        BUILD_TYPE: prebuilt
        BASE_IMAGE: python:3.11-slim
        PYTORCH_VERSION: 2.9.1
        PYTHON_VERSION: 3.11
    image: deepiri-dev-cyrex:latest
    pull_policy: never
    container_name: deepiri-cyrex-ai
    restart: unless-stopped
    logging: *minimal-logging
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OPENAI_MODEL: ${OPENAI_MODEL:-gpt-4o-mini}
      CORS_ORIGIN: http://localhost:5173
      CYREX_API_KEY: ${CYREX_API_KEY:-change-me}
      MLFLOW_TRACKING_URI: ${MLFLOW_TRACKING_URI:-http://mlflow:5000}
      WANDB_API_KEY: ${WANDB_API_KEY}
      MODEL_REGISTRY_PATH: /app/model_registry
      STAGING_MODEL_PATH: /app/models/staging
      PRODUCTION_MODEL_PATH: /app/models/production
      PINECONE_API_KEY: ${PINECONE_API_KEY}
      PINECONE_ENVIRONMENT: ${PINECONE_ENVIRONMENT:-us-east1-gcp}
      PINECONE_INDEX: ${PINECONE_INDEX:-deepiri}
      WEAVIATE_URL: ${WEAVIATE_URL}
      INFLUXDB_URL: http://influxdb:8086
      INFLUXDB_TOKEN: ${INFLUXDB_TOKEN}
      INFLUXDB_ORG: ${INFLUXDB_ORG:-deepiri}
      INFLUXDB_BUCKET: ${INFLUXDB_BUCKET:-analytics}
      MILVUS_HOST: milvus
      MILVUS_PORT: 19530
      TRANSFORMERS_CACHE: /app/.cache/huggingface
      HF_HOME: /app/.cache/huggingface
      SENTENCE_TRANSFORMERS_HOME: /app/.cache/sentence_transformers
    ports:
      - "8000:8000"
    volumes:
      - ./diri-cyrex/app:/app/app
      - ./diri-cyrex/train:/app/train
      - ./diri-cyrex/inference:/app/inference
      - cyrex_ai_cache:/app/.cache
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload --reload-dir /app/app
    depends_on:
      - influxdb
      - milvus
    networks:
      - deepiri-ai-network

  # Cyrex Interface (Frontend)
  cyrex-interface:
    image: node:20-alpine
    container_name: deepiri-cyrex-interface-ai
    restart: unless-stopped
    logging: *minimal-logging
    working_dir: /app
    environment:
      VITE_CYREX_BASE_URL: http://cyrex:8000
      VITE_PORT: 5175
    ports:
      - "5175:5175"
    volumes:
      - ./diri-cyrex/cyrex-interface:/app
      - /app/node_modules
    command: sh -c "npm install --legacy-peer-deps && npm run dev -- --host 0.0.0.0 --port ${VITE_PORT:-5175}"
    depends_on:
      - cyrex
    networks:
      - deepiri-ai-network

  # MLflow for AI Experiment Tracking
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.8.1
    container_name: deepiri-mlflow-ai
    restart: unless-stopped
    logging: *minimal-logging
    ports:
      - "5500:5000"
    environment:
      BACKEND_STORE_URI: file:/mlflow
      DEFAULT_ARTIFACT_ROOT: file:/mlflow/artifacts
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri file:/mlflow --default-artifact-root file:/mlflow/artifacts
    volumes:
      - mlflow_ai_data:/mlflow
    networks:
      - deepiri-ai-network

  # Jupyter Notebook for AI Research
  jupyter:
    build:
      context: ./diri-cyrex
      dockerfile: Dockerfile.jupyter
      args:
        BUILD_TYPE: prebuilt
        BASE_IMAGE: python:3.11-slim
        PYTORCH_VERSION: 2.9.1
        PYTHON_VERSION: 3.11
    image: deepiri-dev-jupyter:latest
    pull_policy: never
    container_name: deepiri-jupyter-ai
    restart: unless-stopped
    logging: *minimal-logging
    command: jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root --NotebookApp.token='' --NotebookApp.password='' --NotebookApp.runtime_dir=/tmp/jupyter_runtime --NotebookApp.notebook_dir=/app/notebooks
    ports:
      - "8888:8888"
    volumes:
      - ./diri-cyrex/train/notebooks:/app/notebooks
      - ./diri-cyrex/train/data:/app/data
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      JUPYTER_RUNTIME_DIR: /tmp/jupyter_runtime
    networks:
      - deepiri-ai-network

  # Challenge Service
  challenge-service:
    build:
      context: ./platform-services
      dockerfile: backend/deepiri-challenge-service/Dockerfile
    image: deepiri-dev-challenge-service:latest
    pull_policy: never
    container_name: deepiri-challenge-service-ai
    restart: unless-stopped
    logging: *minimal-logging
    ports:
      - "5007:5007"
    environment:
      NODE_ENV: development
      PORT: 5007
      MONGO_URI: mongodb://${MONGO_ROOT_USER:-admin}:${MONGO_ROOT_PASSWORD:-password}@mongodb:27017/${MONGO_DB:-deepiri}?authSource=admin
      CYREX_URL: http://cyrex:8000
    volumes:
      - ./platform-services/backend/deepiri-challenge-service:/app
      - ./platform-services/shared/deepiri-shared-utils:/shared-utils
      - /app/node_modules
    command: sh -c "cd /shared-utils && npm install --legacy-peer-deps && npm run build && cd /app && npm install --legacy-peer-deps file:/shared-utils && npm run dev"
    depends_on:
      - mongodb
      - cyrex
    networks:
      - deepiri-ai-network

volumes:
  mongodb_ai_data:
    driver: local
  redis_ai_data:
    driver: local
  mlflow_ai_data:
    driver: local
  influxdb_ai_data:
    driver: local
  milvus_ai_data:
    driver: local
  etcd_ai_data:
    driver: local
  minio_ai_data:
    driver: local
  cyrex_ai_cache:
    driver: local

networks:
  deepiri-ai-network:
    driver: bridge

